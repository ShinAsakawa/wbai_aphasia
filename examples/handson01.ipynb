{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WBAI Aphasia (Pure Alexia) Handson 01\n",
    "<!-- green '#007879' -->\n",
    "\n",
    "<br>\n",
    "<div align='center'>\n",
    "    <font size='+2' color='#0070FF' align='right'>17/Sep/2018</font><br><br>\n",
    "<!--<font size='+2' color='#0070FF' align='center'><strong>浅川 伸一</strong> &lt;asakawa@ieee.org&gt;</font>-->\n",
    "    <font size='+2' color='#0070FF' align='center'><strong><a href=\"http://www.cis.twcu.ac.jp/~asakawa/\">浅川 伸一</a> &lt;asakawa@ieee.org&gt;</strong></font>\n",
    "    <br><br>\n",
    "</div>\n",
    "<br>\n",
    "<img src='https://wba-initiative.org/wp-content/uploads/2015/05/logo.png' width='29%' align='cener'>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"./assets/Elman-portrait.jpg\" width=\"49%\" align='center'>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRN\n",
    "\n",
    "SRN の基本は以下の式である。\n",
    "\\begin{equation}\n",
    "\\mathbf{y} = \\sigma\\left(\\mathbf{Xw}_{in}+\\mathbf{Hw}_{rec}+\\mathbf{b}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "ここで $\\mathbf{X}$ はデータ行列で $n$ 行，$d$ 列 のデータ行列である。一時刻あたり一行のデータである。\n",
    "時間発展を考えると $\\mathbf{X}$ は逐次実行してまず $\\mathbf{H}$ を作らなければならない。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- リカレントニューラルネットワークの本質として，一時刻前の情報を保持しておく機構がネットワーク内に存在していることが挙げられる。\n",
    "- 時間展開した図\n",
    "\n",
    "<center>\n",
    "    <img src=\"./assets/unfolding_RNN.png\" width=\"39%\">\n",
    "    <img src=\"./assets/2015Bullinaria_Unfolding.png\" width=\"74%\">\n",
    "    </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#from __future__ import print_function\n",
    "#from six.moves import range\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import codecs\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import wbai_aphasia as handson\n",
    "from wbai_aphasia import xavier_initializer\n",
    "from wbai_aphasia import sigmoid, tanh, relu, elu, identity, softsign, softplus, sat, clu\n",
    "from wbai_aphasia import fc_layer, softmax_layer, srn_layer\n",
    "from wbai_aphasia import fetch_mnist, view_mnist\n",
    "from wbai_aphasia import one_hot_vector, txt2data\n",
    "#from wbai_aphasia import cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Sep 17 03:42:54 JST 2018\n",
      "\n",
      "Darwin Himalia.local 17.7.0 Darwin Kernel Version 17.7.0: Thu Jun 21 22:53:14 PDT 2018; root:xnu-4570.71.2~1/RELEASE_X86_64 x86_64\n",
      "\n",
      "python is /Users/asakawa/anaconda3/bin/python\n",
      "\n",
      "Python 3.6.6\n",
      "\n",
      "Configured with: --prefix=/Library/Developer/CommandLineTools/usr --with-gxx-include-dir=/usr/include/c++/4.2.1\n",
      "Apple LLVM version 9.1.0 (clang-902.0.39.2)\n",
      "Target: x86_64-apple-darwin17.7.0\n",
      "Thread model: posix\n",
      "InstalledDir: /Library/Developer/CommandLineTools/usr/bin\n",
      "\n",
      "conda 4.5.11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!date; printf '\\n'\n",
    "!uname -a; printf '\\n'\n",
    "!type python; printf '\\n'\n",
    "!python --version; printf '\\n'\n",
    "!gcc --version; printf '\\n'\n",
    "!conda --version; printf '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### preparation to draw graphs\n",
    "plt.rcParams['figure.figsize'] = (12, 8) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "np.random.seed(seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class elman(object):\n",
    "    \"\"\"A simple elman network model demo.\n",
    "\n",
    "    Parameters:\n",
    "        hidden_layer_sizes : tuple, length = n_layers - 2, default (100,)\n",
    "            The ith element represents the number of neurons in the ith\n",
    "            hidden layer.\n",
    "\n",
    "        activation : {identity, sigmoid, tanh, relu, elu, clu}, default tanh\n",
    "            Activation function for the hidden layer.\n",
    "\n",
    "        solver : {'sgd', 'adagrad', 'adadelta, 'rmsprop, 'adam', 'nadam'}, \n",
    "            default 'adam'.  The solver for weight optimization. \n",
    "            **NOT IMPLEMENTED**\n",
    "\n",
    "        lambda_ : float, optional, default 1e-4\n",
    "            L2 penalty (regularization term) parameter.\n",
    "\n",
    "        lr : the learning ratio: float\n",
    "        lr_init: float, default 1e-2\n",
    "        \n",
    "        random_state : int, RandomState instance or None, optional, default None\n",
    "            If int, random_state is the seed used by the random number generator;\n",
    "            If RandomState instance, random_state is the random number generator;\n",
    "            If None, the random number generator is the RandomState instance used\n",
    "            by `np.random`.\n",
    "\n",
    "        tol : float, optional, default 1e-4\n",
    "            Tolerance for the optimization. When the loss or score is not improving\n",
    "            by at least tol for two consecutive iterations, unless `learning_rate`\n",
    "            is set to 'adaptive', convergence is considered to be reached and\n",
    "            training stops.\n",
    "\n",
    "        verbose : bool, optional, default False\n",
    "            Whether to print progress messages to stdout.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, X, y, \\\n",
    "                 n_hid=128, \\\n",
    "                 max_iter=1e+3, \\\n",
    "                 lr=1e-2, \\\n",
    "                 activation=tanh, \\\n",
    "                 verbose=False):\n",
    "        self.max_iter = max_iter if max_iter is not None else 200\n",
    "        self.n_hid = n_hid if n_hid is not None else 128\n",
    "        self.X, self.y = np.copy(X), np.copy(y)\n",
    "        self.activation = activation if activation is not None else tanh\n",
    "        self.verbose = verbose if verbose is not None else False\n",
    "\n",
    "        self.n_inp = self.X.shape[1]\n",
    "        self.n_out = self.n_inp\n",
    "        self.H = srn_layer(self.n_inp, self.n_hid, activation=activation)\n",
    "        self.O = softmax_layer(self.n_hid, self.n_out)\n",
    "\n",
    "    def fit(self, X, y, lr=1e-2, max_iter=1000, verbose=False):\n",
    "        \"\"\"Fit the model to data matrix X and target y.\n",
    "\n",
    "        Parameters:\n",
    "            X : array-like or sparse matrix, shape (n_samples, n_features)\n",
    "                The input data.\n",
    "\n",
    "            y : array-like, shape (n_samples,) or (n_samples, n_outputs)\n",
    "                The target values (class labels in classification).\n",
    "\n",
    "        Returns:\n",
    "            self : returns a trained MLP model.\n",
    "        \"\"\"\n",
    "        return self.train(X, y, max_iter=max_iter, verbose=verbose)\n",
    "\n",
    "     \n",
    "    def train(self, X, y, lr=1e-2, max_iter=1000, verbose=False):\n",
    "        \"\"\"Train the model to data matrix X and target y.\n",
    "\n",
    "        Parameters:\n",
    "            X : array-like or sparse matrix, shape (n_samples, n_features)\n",
    "                The input data.\n",
    "\n",
    "            y : array-like, shape (n_samples,) or (n_samples, n_outputs)\n",
    "                The target values (class labels in classification).\n",
    "\n",
    "        Returns:\n",
    "            self : returns a trained the Elman network model.\n",
    "        \"\"\"\n",
    "        X = self.X if X is None else X\n",
    "        y = self.y if y is None else y\n",
    "        verbose = verbose if verbose is not None else self.verbose\n",
    "        max_iter = max_iter if max_iter is not None else self.max_iter\n",
    "        hInit = np.zeros((1, self.n_hid),dtype=np.float32)\n",
    "        state = np.zeros((X.shape[0],self.n_hid),dtype=np.float32)\n",
    "        lossList = list()\n",
    "        for t in range(max_iter):\n",
    "            inp = X\n",
    "            Hout, state = self.H.forward(X, state, hInit)\n",
    "            y_ = self.O.forward(Hout)\n",
    "\n",
    "            Err = y_ - y\n",
    "            #loss = np.mean(Err**2)\n",
    "            loss = handson.binary_log_loss(y,y_)\n",
    "            lossList.append(loss)\n",
    "            if (t % (max_iter>>3) == 0) and verbose:\n",
    "                #print('Iter={0:05d} loss={1:0.3f}'.format(iter, loss))\n",
    "                p = np.argmax(y,axis=0)\n",
    "                p_ = np.argmax(y_,axis=0)\n",
    "                accuracy = np.average(p == p_)\n",
    "                print('Iter={0:05d} loss={1:0.4f}, cost={2:0.4f}, accuracy={3:0.4f}'.format(\n",
    "                    t, \n",
    "                    loss,\n",
    "                    handson.cost(y_),\n",
    "                    accuracy))\n",
    "            delta = Err\n",
    "            gradW2 = self.O.backward(delta, Hout)\n",
    "            delta = np.dot(delta, self.O.W.T)\n",
    "            gradW1, gradWr, _ = self.H.backward(X, state, delta)\n",
    "    \n",
    "            self.O.W -= lr * gradW2\n",
    "            self.O.bias -= lr * np.mean(gradW2)\n",
    "            self.H.W -= lr * gradW1\n",
    "            self.H.bias -= lr * np.mean(gradW1)\n",
    "            self.H.Wr -= lr * gradWr\n",
    "        \n",
    "        if verbose:\n",
    "            plt.plot(lossList)\n",
    "            #plt.show()\n",
    "            print('#Target: ', end='')\n",
    "            for x in y:\n",
    "                print(idx2wrd[np.argmax(x)],end='')\n",
    "            print('\\n#Output: ', end='')\n",
    "            for x in y_:\n",
    "                print(idx2wrd[np.argmax(x)],end='')\n",
    "            print()    \n",
    "            \n",
    "        return y_, lossList\n",
    "\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict using this elman neural network.\n",
    "\n",
    "        Parameters:\n",
    "            X : {array-like, matrix}, shape (n_samples, n_features)\n",
    "            The input data.\n",
    "\n",
    "        Returns:\n",
    "            y : array-like, shape (n_samples,) or (n_samples, n_classes)\n",
    "            The predicted classes.\n",
    "        \"\"\"\n",
    "\n",
    "        hInit = np.zeros((1, self.n_hid),dtype=np.float32)\n",
    "        state = np.zeros((X.shape[0],self.n_hid),dtype=np.float32)\n",
    "        Hout, state = self.H.forward(X, state, hInit)\n",
    "        y_ = self.O.forward(Hout)\n",
    "        return y_\n",
    "\n",
    "    \n",
    "    def predict_log_prob(self, X):\n",
    "        \"\"\"Return the log of probability estimates.\n",
    "\n",
    "        Parameters:\n",
    "            X : array-like, shape (n_samples, n_features)\n",
    "                The input data.\n",
    "\n",
    "        Returns:\n",
    "            log_y_prob : array-like, shape (n_samples, n_classes)\n",
    "                The predicted log-probability of the sample for each class\n",
    "                in the model, where classes are ordered as they are in\n",
    "                `self.classes_`. Equivalent to log(predict_proba(X))\n",
    "        \"\"\"\n",
    "        yprob_ = self.predict_prob(X)\n",
    "        return np.log(yprob_, out=yprob_)\n",
    "\n",
    "    def predict_prob(self, X):\n",
    "        \"\"\"Probability estimates.\n",
    "\n",
    "        Parameters:\n",
    "            X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
    "                The input data.\n",
    "\n",
    "        Returns:\n",
    "            y_prob : array-like, shape (n_samples, n_classes)\n",
    "                The predicted probability of the sample for each class in the\n",
    "                model, where classes are ordered as they are in `self.classes_`.\n",
    "        \"\"\"\n",
    "        y_ = self._predict(X)\n",
    "\n",
    "        if self.n_outputs_ == 1:\n",
    "            y_ = y_.ravel()\n",
    "\n",
    "        if y_.ndim == 1:\n",
    "            return np.vstack([1 - y_, y_]).T\n",
    "        else:\n",
    "            return y_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename=basyo.txt\n",
      "Iter=00000 loss=5.9167, cost=4.9252, accuracy=0.0000\n",
      "Iter=00125 loss=2.0057, cost=7.4214, accuracy=0.3556\n",
      "Iter=00250 loss=1.7492, cost=8.9311, accuracy=0.3556\n",
      "Iter=00375 loss=1.7292, cost=9.5244, accuracy=0.3630\n",
      "Iter=00500 loss=1.7245, cost=9.8053, accuracy=0.3556\n",
      "Iter=00625 loss=1.7549, cost=9.9707, accuracy=0.3556\n",
      "Iter=00750 loss=1.7295, cost=9.9695, accuracy=0.3630\n",
      "Iter=00875 loss=1.7442, cost=9.8522, accuracy=0.3704\n",
      "#Target: 日は百代の過客にして、行き交ふ年もまた旅人なり。船の上に生涯を浮かべ、馬の口とらへて老いを迎ふる者は、日々旅にして旅を栖とす。古人も多く旅に死せるあり。</s>予もいづれの年よりか、片雲の風に誘はれて、漂白の思ひやまず、海浜にさすらへ、去年の秋、江上の破屋に蜘蛛の古巣をはらひて、やや年も暮れ、春立てる霞の空に、白河の関越えんと、そぞろ神の物につきて心を狂はせ、道祖神の招きにあひて取るもの手につかず、股引の破れをづづり、笠の緒付けかへて、三里に灸すゆるより、松島の月まづ心にかかりて、住める方は人に譲り、杉風が別所に移るに、</s></s>草の戸も住み替はる代ぞ雛の家</s></s>表八句を庵の柱に掛け置く。</s>月\n",
      "#Output: 日々人代の破客につて、江き交ふ年もいず旅にもり、</s>の破につ涯を栖かり、江の破とすへて、いづ栖ふ年方は人江々旅につて、に栖とすゆ</s>巣もいく。につせ、方ひ、</s></s>もいづれ、破もり、り江雲の破がつは人、、江白河破ひて年ず、江浜につすゆへて江年も破、江上に破れにつ蛛の破巣を栖人へて、江年年もいれ、江立て、方の破につ江河の破越えんとす江ぞろ神の破につか交、を栖は人、江祖神の破き交つひて、る方い破につかり、江引の破れ、栖れれ、江の破付けかりて、江里につすゆる方り、江島の破まずれをつりり、、江める方は人もつり、江風が別所につる方つ江</s></s>の破もいめ替は人方のろの破</s></s></s>八句を栖の破につけかく。</s></s>\n",
      "time elasped 112.91213202476501\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "filename = 'j_constitution9.txt'\n",
    "filename = 'basyo.txt'\n",
    "nHid = 128\n",
    "activation = tanh\n",
    "max_iter = 1000\n",
    "lr = 1e-2\n",
    "X, y, idx2wrd, wrd2idx = txt2data(filename)\n",
    "model = elman(X, y, n_hid=nHid, lr=lr, max_iter=max_iter, activation=activation)\n",
    "start_time = time.time()\n",
    "y_, lossList = model.train(X, y, max_iter=max_iter,verbose=True)\n",
    "#y_, _ = model.fit(X, y, max_iter=max_iter, verbose=True)\n",
    "end_time = time.time()\n",
    "print('time elasped {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(filename=None, max_iter=1000, nHid=16, activation=tanh, lr=1e-2, verbose=False):\n",
    "    X, y, idx2wrd, wrd2idx = txt2data(filename)\n",
    "    model = elman(X, y, n_hid=nHid, lr=lr, max_iter=max_iter, activation=tanh, verbose=verbose)\n",
    "    y_, lossList = model.train(X, y, max_iter=max_iter, verbose=verbose)\n",
    "    \n",
    "    return model, X, y_, lossList, idx2wrd, wrd2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Simple demo for both MLP and SRN')\n",
    "    parser.add_argument('--seed', type=int, default=1, help='# Seed number to gerenrate random number sequence.')\n",
    "    parser.add_argument('--max_iter', type=int, default=1000, help='# maximum number of iteration.')\n",
    "    parser.add_argument('--nHid', type=int, default=32, help='# The number of the hidden unints.')\n",
    "    parser.add_argument('--lr', type=float, default=1e-2, help='# Learning ratio.')\n",
    "    parser.add_argument('--activation', default='tanh', help='# activation function')\n",
    "    #parser.add_argument('--filename', default=__file__, help='# The input text file name')\n",
    "    parser.add_argument('--filename', default='j_constitution9.txt', help='# The input text file name')\n",
    "    parser.add_argument('--verbose', action='store_false', help='# Verbose flag for debug')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    if args.seed:\n",
    "        seed = args.seed\n",
    "    if args.max_iter:\n",
    "        max_iter = args.max_iter\n",
    "    if args.nHid:\n",
    "        nHid = args.nHid\n",
    "    if args.lr:\n",
    "        lr = args.lr\n",
    "    if args.activation:\n",
    "        activation=args.activation\n",
    "    if args.filename:\n",
    "        filename=args.filename\n",
    "    if args.verbose:\n",
    "        verbose=True\n",
    "\n",
    "    main(filename=filename, max_iter=max_iter, nHid=nHid, activation=activation, lr=lr, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
